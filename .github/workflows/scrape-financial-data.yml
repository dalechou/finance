name: Web Scraping Financial Data

on:
  schedule:
    - cron: '0 0 * * *' # Daily at midnight UTC
  workflow_dispatch:  # Allows manual trigger

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
    # Step 1: Checkout repository
    - name: Checkout repository
      uses: actions/checkout@v2

    # Step 2: Set up Node.js
    - name: Set up Node.js
      uses: actions/setup-node@v2
      with:
        node-version: '16'  # Use Node.js 16 or later for ES Modules support

    # Step 3: Install dependencies (node-fetch)
    - name: Install dependencies
      run: |
        npm install node-fetch  # Install node-fetch (v3)

    # Step 4: Run the scraper script
    - name: Run the scraper script
      run: |
        node scraper.mjs  # Run the .mjs file

    # Step 5: Ensure CSV file is tracked and commit changes
    - name: Ensure CSV file is tracked and commit changes
      run: |
        # Check if financial_data.csv exists
        if [ -f financial_data.csv ]; then
          echo "CSV file found. Checking git status."
          
          # Check for changes to the CSV file
          git status
          
          # Add any modified or new files to the commit
          git add financial_data.csv
          
          # Check if there are any changes to commit
          if ! git diff --cached --exit-code; then
            echo "Changes detected, committing and pushing."
            git config --global user.name "GitHub Actions"
            git config --global user.email "actions@github.com"
            git commit -m "Update financial data CSV"
            git push
          else
            echo "No changes to commit."
          fi
        else
          echo "No CSV file to commit."
        fi
