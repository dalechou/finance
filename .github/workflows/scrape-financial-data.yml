name: Web Scraping Financial Data

on:
  schedule:
    # Runs at midnight every day (set to run once a week by changing the cron expression)
    - cron: '0 0 * * *' # This will run once every day at midnight (UTC)
    # Uncomment the line below to run it once a week instead (at midnight Sunday)
    # - cron: '0 0 * * 0'

  # Allow manual trigger as well
  workflow_dispatch:

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
    # Step 1: Check out the repository
    - name: Checkout repository
      uses: actions/checkout@v2

    # Step 2: Set up Node.js environment
    - name: Set up Node.js
      uses: actions/setup-node@v2
      with:
        node-version: '16'  # You can specify the version of Node.js you want to use

    # Step 3: Install dependencies
    - name: Install dependencies
      run: |
        npm install node-fetch  # Install the 'node-fetch' package to make API calls

    # Step 4: Run the scraper script
    - name: Run the scraper script
      run: |
        node scraper.js  # This will run the scraper.js file we created earlier

    # Step 5: Commit the generated CSV file back to the repository
    - name: Commit CSV file
      run: |
        git config --global user.name "GitHub Actions"
        git config --global user.email "actions@github.com"
        git add financial_data.csv
        git commit -m "Update financial data CSV"
        git push
